import requests # type: ignore
import os
import re
from dotenv import load_dotenv # type: ignore
from datetime import datetime, timedelta

load_dotenv()
slack_webhook_url = os.getenv("SLACK_WEBHOOK_URL")

# Qiita APIã‹ã‚‰è¨˜äº‹å–å¾—
def get_qiita_articles(tag="python", per_page=3):
    url = f"https://qiita.com/api/v2/tags/{tag}/items"
    params = {"per_page": per_page}
    response = requests.get(url, params=params)
    if response.status_code == 200:
        return response.json()
    else:
        print(f"ã‚¨ãƒ©ãƒ¼ ({tag}) : {response.status_code}")
        return []

# Slackã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡
def send_slack_notification(message, webhook_url):
    payload = {
        "text": message
    }
    response = requests.post(webhook_url, json=payload)
    if response.status_code != 200:
        print("Slacké€šçŸ¥å¤±æ•—:", response.text)

# ä»¥å‰é€šçŸ¥ã—ãŸURLã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
def load_notified_urls(file_path="notified_urls.txt"):
    if os.path.exists(file_path):
        with open(file_path, "r") as file:
            return set(
                line.strip()
                for line in file
                if line.strip() and not line.startswith("##")
            )
    return set()

# æ–°ã—ãé€šçŸ¥ã™ã¹ãè¨˜äº‹ã¨ã€é€šçŸ¥æ¸ˆã¿è¨˜äº‹ã‚’åˆ¤åˆ¥
def filter_new_articles(articles, notified_urls):
    new_articles = []
    new_urls = []
    for article in articles:
        if article["url"] not in notified_urls:
            new_articles.append(article)
            new_urls.append(article["url"])
    return new_articles, new_urls

# æ–°ãŸã«é€šçŸ¥ã—ãŸURLã‚’æ—¥ä»˜ä»˜ãã§ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½è¨˜ã™ã‚‹
def save_notified_urls_with_date(urls, file_path="notified_urls.txt"):
    if not urls:
        return

    today_str = datetime.now().strftime("%Y-%m-%d")
    dated_block = f"## {today_str}\n" + "\n".join(urls) + "\n"

    # 1. æ—¢å­˜å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
    if os.path.exists(file_path):
        with open(file_path, "r") as file:
            existing_data = file.read()
    else:
        existing_data = ""

    # 2. æ—¢å­˜å†…å®¹ã«è¿½åŠ ï¼ˆåŒæ—¥é‡è¤‡é˜²æ­¢ï¼‰
    if f"## {today_str}" in existing_data:
        # åŒæ—¥ãƒ–ãƒ­ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯è¿½è¨˜ã›ãšã‚¹ã‚­ãƒƒãƒ—ï¼ˆã¾ãŸã¯ä¸Šæ›¸ãã—ãŸã‘ã‚Œã°èª¿æ•´ï¼‰
        return

    new_data = existing_data + "\n" + dated_block

    # 3. å¤ã„ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆ7æ—¥ã‚ˆã‚Šå‰ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤ï¼‰
    new_data = remove_old_blocks(new_data, keep_days=7)

    with open(file_path, "w") as file:
        file.write(new_data.strip() + "\n")

# éå»å±¥æ­´ã‚’å‰Šé™¤
def remove_old_blocks(text, keep_days=7):
    blocks = re.findall(r"(## (\d{4}-\d{2}-\d{2})\n(?:[^\#]*?))(?=(?:## |\Z))", text, re.MULTILINE)
    today = datetime.now().date()
    kept_blocks = []

    for block, date_str in blocks:
        try:
            block_date = datetime.strptime(date_str, "%Y-%m-%d").date()
            if (today - block_date).days <= keep_days:
                kept_blocks.append(block.strip())
        except ValueError:
            continue  # æ—¥ä»˜ãŒå£Šã‚Œã¦ãŸã‚‰ã‚¹ã‚­ãƒƒãƒ—

    return "\n\n".join(kept_blocks)

# äººæ°—ã®è¨˜äº‹ã‚’å–å¾—ã™ã‚‹
def get_popular_qiita_articles(tag="python", per_page=20, min_likes=10, top_n=5):
    query = f"tag:{tag} stocks:>={min_likes}"
    url = "https://qiita.com/api/v2/items"
    params = {
        "per_page": per_page,
        "page": 1,
        "query": query
    }
    response = requests.get(url, params=params)
    if response.status_code == 200:
        articles = response.json()
        sorted_articles = sorted(articles, key=lambda x: x["likes_count"], reverse=True)
        return sorted_articles[:top_n]
    else:
        print(f"äººæ°—è¨˜äº‹ã®å–å¾—å¤±æ•— ({tag}): {response.status_code}")
        return []


# ãƒ¡ã‚¤ãƒ³å‡¦ç†
if __name__ == "__main__":
    # è¤‡æ•°ã®ã‚¿ã‚°ã‚’æŒ‡å®š
    tags = ["python", "AI"]
    
    # é€šçŸ¥æ¸ˆã¿URLã‚’èª­ã¿è¾¼ã‚€
    notified_urls = load_notified_urls()

    all_new_urls = []
    slack_message = ""

    for tag in tags:
        # --- æ–°è¦è¨˜äº‹ã®å–å¾—ã¨é€šçŸ¥ ---
        articles = get_qiita_articles(tag, 5)
        # æ–°ã—ã„è¨˜äº‹ã¨é€šçŸ¥æ¸ˆã¿URLã‚’åˆ†ã‘ã‚‹
        new_articles, new_urls = filter_new_articles(articles, notified_urls)

        if new_articles:
            slack_message += f":label: *#{tag} ã®æ–°ç€è¨˜äº‹*\n"
            for article in new_articles:
                slack_message += f"â€¢ <{article['url']}|{article['title']}>\n"
            all_new_urls.extend(new_urls)
        else:
            slack_message += f":label: *#{tag} ã®æ–°è¦è¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚*\n"
        
        # --- äººæ°—è¨˜äº‹ã®å–å¾—ã¨é€šçŸ¥ ---
        popular_articles = get_popular_qiita_articles(tag, per_page=20, min_likes=10, top_n=5)
        if popular_articles:
            slack_message += f"\n:star: *#{tag} ã®äººæ°—è¨˜äº‹TOP{len(popular_articles)}*\n"
            for i, article in enumerate(popular_articles, start=1):
                slack_message += f"{i}. <{article['url']}|{article['title']}>ï¼ˆğŸ‘ {article['likes_count']}ï¼‰\n"
    
    # Slacké€šçŸ¥ã‚’é€ä¿¡
    if slack_message:
        send_slack_notification(slack_message.strip(), slack_webhook_url)
        print("Slacké€šçŸ¥ã‚’é€ã‚Šã¾ã—ãŸ âœ…")
    
    # é€šçŸ¥æ¸ˆã¿URLã®ä¿å­˜
    if all_new_urls:
        save_notified_urls_with_date(all_new_urls)
